import os
import csv
import subprocess
import logging
from dotenv import load_dotenv
import shutil

# Load environment variables
load_dotenv()

# Setup logging
LOG_FILE = "large_file_scan_verbose.log"
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

def log_and_print(message):
    print(message)
    logging.info(message)

# Constants
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
INPUT_CSV = "urlTestGreater.csv"
OUTPUT_CSV = "large_files_report.csv"
CLONE_DIR = "cloned_repos"
SIZE_THRESHOLD = 419430400  # 400MB

os.makedirs(CLONE_DIR, exist_ok=True)

output_rows = [["Repo URL", "Clone Status", "Scan Status", "Large Files (path, size, commit, branches)", "Error", "Total Branches Scanned"]]

# Read repo URLs
with open(INPUT_CSV, newline='') as infile:
    reader = csv.reader(infile)
    urls = [row[0].strip() for row in reader if row]

for url in urls:
    repo_name = url.split("/")[-1].replace(".git", "")
    clone_path = os.path.join(CLONE_DIR, repo_name)

    if os.path.exists(clone_path):
        shutil.rmtree(clone_path)

    authed_url = url.replace("https://", f"https://{GITHUB_TOKEN}@")

    clone_status = "Failed"
    scan_status = "Not Started"
    error_message = ""
    total_branches = 0
    large_files_info = []

    try:
        subprocess.run(["git", "clone", "--mirror", authed_url, clone_path],
                       check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        log_and_print(f"CLONE SUCCESS: {url}")
        clone_status = "Success"

        try:
            # Get all branches
            branches = subprocess.check_output(["git", "for-each-ref", "--format=%(refname:short)", "refs/heads"],
                                               cwd=clone_path).decode().splitlines()
            total_branches = len(branches)
            log_and_print(f"Scanning {total_branches} branches in {url}...")

            seen_blobs = {}

            for branch in branches:
                log_and_print(f"Branch: {branch}")
                commits = subprocess.check_output(["git", "rev-list", branch], cwd=clone_path).decode().splitlines()
                for commit in commits:
                    tree_output = subprocess.check_output(["git", "ls-tree", "-r", commit], cwd=clone_path).decode().splitlines()
                    for line in tree_output:
                        parts = line.split()
                        if len(parts) < 4:
                            continue
                        blob_hash = parts[2]
                        file_path = parts[3]

                        if blob_hash in seen_blobs:
                            seen_blobs[blob_hash]["branches"].add(branch)
                            continue

                        try:
                            size = int(subprocess.check_output(["git", "cat-file", "-s", blob_hash], cwd=clone_path).decode().strip())
                            if size > SIZE_THRESHOLD:
                                seen_blobs[blob_hash] = {
                                    "path": file_path,
                                    "size": size,
                                    "commit": commit,
                                    "branches": {branch}
                                }
                        except Exception:
                            continue

            for blob in seen_blobs.values():
                large_files_info.append(
                    f"{blob['path']} ({blob['size']} bytes, commit: {blob['commit']}, branches: {', '.join(blob['branches'])})"
                )

            scan_status = "Completed"
            if not large_files_info:
                large_files_info = ["None"]

            log_and_print(f"SCAN COMPLETE: {url} - Files over 400MB: {len(large_files_info)}")

        except subprocess.CalledProcessError as e:
            scan_status = "Failed"
            error_message = e.stderr.decode()
            log_and_print(f"SCAN FAILED: {url} — {error_message}")

    except subprocess.CalledProcessError as e:
        error_message = e.stderr.decode()
        log_and_print(f"CLONE FAILED: {url} — {error_message}")

    output_rows.append([
        url,
        clone_status,
        scan_status,
        "; ".join(large_files_info),
        error_message,
        total_branches
    ])

# Write results to CSV
with open(OUTPUT_CSV, "w", newline='') as outfile:
    writer = csv.writer(outfile)
    writer.writerows(output_rows)
