import os
import csv
import subprocess
import logging
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Setup logging
LOG_FILE = "large_file_scan.log"
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

def log_and_print(message):
    print(message)
    logging.info(message)

# Constants
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
INPUT_CSV = "urlTestGreater.csv"
OUTPUT_CSV = "large_files_report.csv"
CLONE_DIR = "cloned_repos"

# Ensure the clone directory exists
os.makedirs(CLONE_DIR, exist_ok=True)

# Read the repository URLs from CSV
with open(INPUT_CSV, newline='') as infile:
    reader = csv.reader(infile)
    urls = [row[0].strip() for row in reader if row]

# Prepare output CSV
with open(OUTPUT_CSV, "w", newline='') as outfile:
    writer = csv.writer(outfile)
    writer.writerow(["Repo URL", "Clone Status", "git-sizer Status", "File Scan Status", "Files Over 400MB", "Error"])

    for url in urls:
        repo_name = url.strip().split("/")[-1].replace(".git", "")
        clone_path = os.path.join(CLONE_DIR, repo_name)
        if os.path.exists(clone_path):
            subprocess.run(["rm", "-rf", clone_path])  # clean up before cloning

        # Inject token into the URL for auth
        authed_url = url.replace("https://", f"https://{GITHUB_TOKEN}@")

        clone_status = "Failed"
        sizer_status = "N/A"
        scan_status = "N/A"
        large_files = ""
        error_message = ""

        try:
            subprocess.run(["git", "clone", "--mirror", authed_url, clone_path], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            log_and_print(f"CLONE SUCCESS: {url}")
            clone_status = "Success"

            # Run git-sizer
            try:
                result = subprocess.run(["git-sizer", "--verbose"], cwd=clone_path, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                sizer_output = result.stdout.decode()
                sizer_status = "Success"
                scan_status = "Completed"

                # Look for files over 400MB (approx. 419430400 bytes)
                large_file_lines = [line for line in sizer_output.splitlines() if "blob" in line and "bytes" in line]
                over_400mb = []
                for line in large_file_lines:
                    parts = line.split()
                    for i in range(len(parts)):
                        if parts[i] == "bytes":
                            try:
                                size = int(parts[i-1])
                                if size > 419430400:
                                    over_400mb.append(line)
                            except:
                                continue
                large_files = "; ".join(over_400mb) if over_400mb else "None"
                log_and_print(f"SCAN COMPLETE: {url} - Large files: {large_files}")

            except subprocess.CalledProcessError as e:
                sizer_status = "Failed"
                error_message = e.stderr.decode()
                log_and_print(f"git-sizer FAILED: {url} — {error_message}")

        except subprocess.CalledProcessError as e:
            error_message = e.stderr.decode()
            log_and_print(f"CLONE FAILED: {url} — {error_message}")

        writer.writerow([url, clone_status, sizer_status, scan_status, large_files, error_message])
